{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C-_jynSgcimv"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install -U langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DvKT3eTjO8U",
        "outputId": "960af9cd-f650-4760-c307-e027e46e1a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gQHYMSnWH6",
        "outputId": "12afb101-2665-42f3-e180-1606a4c720b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/137.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jH_vdxPjTIE",
        "outputId": "3f44705d-cfda-4cd8-e910-5f704cf89ba9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yHHU0fPynekP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MXJ2FZVvFKAu"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = str(os.getenv(\"LANGCHAIN_API_KEY\"))\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"TEST LLM\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PBzCAfJ8d9Xz"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup as Soup\n",
        "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "\n",
        "# LCEL docs\n",
        "url = \"https://python.langchain.com/docs/expression_language/\"\n",
        "loader = RecursiveUrlLoader(\n",
        "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "# LCEL w/ PydanticOutputParser (outside the primary LCEL docs)\n",
        "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
        "loader = RecursiveUrlLoader(\n",
        "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
        ")\n",
        "docs_pydantic = loader.load()\n",
        "\n",
        "# LCEL w/ Self Query (outside the primary LCEL docs)\n",
        "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
        "loader = RecursiveUrlLoader(\n",
        "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
        ")\n",
        "docs_sq = loader.load()\n",
        "\n",
        "# Add\n",
        "docs.extend([*docs_pydantic, *docs_sq])\n",
        "\n",
        "# Sort the list based on the URLs in 'metadata' -> 'source'\n",
        "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
        "d_reversed = list(reversed(d_sorted))\n",
        "\n",
        "# Concatenate the 'page_content' of each sorted dictionary\n",
        "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
        "    [doc.page_content for doc in d_reversed]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FwrXRctPeT--"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        keys: A dictionary where each key is a string.\n",
        "    \"\"\"\n",
        "\n",
        "    keys: Dict[str, any]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NGTTgoe8en2w"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uEpNJtLTesBI"
      },
      "outputs": [],
      "source": [
        "def generate(state: GraphState):\n",
        "    \"\"\"\n",
        "    Generate a code solution based on LCEL docs and the input question\n",
        "    with optional feedback from code execution tests\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "\n",
        "    ## State\n",
        "    state_dict = state[\"keys\"]\n",
        "    question = state_dict[\"question\"]\n",
        "    iter = state_dict[\"iterations\"]\n",
        "\n",
        "    ## Data model\n",
        "    class code(BaseModel):\n",
        "        \"\"\"Code output\"\"\"\n",
        "\n",
        "        prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "        imports: str = Field(description=\"Code block import statements\")\n",
        "        code: str = Field(description=\"Code block not including import statements\")\n",
        "\n",
        "    ## LLM\n",
        "    model = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "    # Tool\n",
        "    code_tool_oai = convert_to_openai_tool(code)\n",
        "\n",
        "    # LLM with tool and enforce invocation\n",
        "    llm_with_tool = model.bind(\n",
        "        tools=[code_tool_oai],\n",
        "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"code\"}},\n",
        "    )\n",
        "\n",
        "    # Parser\n",
        "    parser_tool = PydanticToolsParser(tools=[code])\n",
        "\n",
        "    ## Prompt\n",
        "    template = \"\"\"You are a coding assistant with expertise in LCEL, LangChain expression language. \\n\n",
        "        Here is a full set of LCEL documentation:\n",
        "        \\n ------- \\n\n",
        "        {context}\n",
        "        \\n ------- \\n\n",
        "        Answer the user question based on the above provided documentation. \\n\n",
        "        Ensure any code you provide can be executed with all required imports and variables defined. \\n\n",
        "        Structure your answer with a description of the code solution. \\n\n",
        "        Then list the imports. And finally list the functioning code block. \\n\n",
        "        Here is the user question: \\n --- --- --- \\n {question}\"\"\"\n",
        "\n",
        "    ## Generation\n",
        "    if \"error\" in state_dict:\n",
        "        print(\"---RE-GENERATE SOLUTION w/ ERROR FEEDBACK---\")\n",
        "\n",
        "        error = state_dict[\"error\"]\n",
        "        code_solution = state_dict[\"generation\"]\n",
        "\n",
        "        # Udpate prompt\n",
        "        addendum = \"\"\"  \\n --- --- --- \\n You previously tried to solve this problem. \\n Here is your solution:\n",
        "                    \\n --- --- --- \\n {generation}  \\n --- --- --- \\n  Here is the resulting error from code\n",
        "                    execution:  \\n --- --- --- \\n {error}  \\n --- --- --- \\n Please re-try to answer this.\n",
        "                    Structure your answer with a description of the code solution. \\n Then list the imports.\n",
        "                    And finally list the functioning code block. Structure your answer with a description of\n",
        "                    the code solution. \\n Then list the imports. And finally list the functioning code block.\n",
        "                    \\n Here is the user question: \\n --- --- --- \\n {question}\"\"\"\n",
        "        template = template + addendum\n",
        "\n",
        "        # Prompt\n",
        "        prompt = PromptTemplate(\n",
        "            template=template,\n",
        "            input_variables=[\"context\", \"question\", \"generation\", \"error\"],\n",
        "        )\n",
        "\n",
        "        # Chain\n",
        "        chain = (\n",
        "            {\n",
        "                \"context\": lambda _: concatenated_content,\n",
        "                \"question\": itemgetter(\"question\"),\n",
        "                \"generation\": itemgetter(\"generation\"),\n",
        "                \"error\": itemgetter(\"error\"),\n",
        "            }\n",
        "            | prompt\n",
        "            | llm_with_tool\n",
        "            | parser_tool\n",
        "        )\n",
        "\n",
        "        code_solution = chain.invoke(\n",
        "            {\"question\": question, \"generation\": str(code_solution[0]), \"error\": error}\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        print(\"---GENERATE SOLUTION---\")\n",
        "\n",
        "        # Prompt\n",
        "        prompt = PromptTemplate(\n",
        "            template=template,\n",
        "            input_variables=[\"context\", \"question\"],\n",
        "        )\n",
        "\n",
        "        # Chain\n",
        "        chain = (\n",
        "            {\n",
        "                \"context\": lambda _: concatenated_content,\n",
        "                \"question\": itemgetter(\"question\"),\n",
        "            }\n",
        "            | prompt\n",
        "            | llm_with_tool\n",
        "            | parser_tool\n",
        "        )\n",
        "\n",
        "        code_solution = chain.invoke({\"question\": question})\n",
        "\n",
        "    iter = iter + 1\n",
        "    return {\n",
        "        \"keys\": {\"generation\": code_solution, \"question\": question, \"iterations\": iter}\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZAO7bLbteyim"
      },
      "outputs": [],
      "source": [
        "def check_code_imports(state: GraphState):\n",
        "    \"\"\"\n",
        "    Check imports\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, error\n",
        "    \"\"\"\n",
        "\n",
        "    ## State\n",
        "    print(\"---CHECKING CODE IMPORTS---\")\n",
        "    state_dict = state[\"keys\"]\n",
        "    question = state_dict[\"question\"]\n",
        "    code_solution = state_dict[\"generation\"]\n",
        "    imports = code_solution[0].imports\n",
        "    iter = state_dict[\"iterations\"]\n",
        "\n",
        "    try:\n",
        "        # Attempt to execute the imports\n",
        "        exec(imports)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
        "        # Catch any error during execution (e.g., ImportError, SyntaxError)\n",
        "        error = f\"Execution error: {e}\"\n",
        "        if \"error\" in state_dict:\n",
        "            error_prev_runs = state_dict[\"error\"]\n",
        "            error = error_prev_runs + \"\\n --- Most recent run error --- \\n\" + error\n",
        "    else:\n",
        "        print(\"---CODE IMPORT CHECK: SUCCESS---\")\n",
        "        # No errors occurred\n",
        "        error = \"None\"\n",
        "\n",
        "    return {\n",
        "        \"keys\": {\n",
        "            \"generation\": code_solution,\n",
        "            \"question\": question,\n",
        "            \"error\": error,\n",
        "            \"iterations\": iter,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nlVY7NsmfOwH"
      },
      "outputs": [],
      "source": [
        "def check_code_execution(state: GraphState):\n",
        "    \"\"\"\n",
        "    Check code block execution\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, error\n",
        "    \"\"\"\n",
        "\n",
        "    ## State\n",
        "    print(\"---CHECKING CODE EXECUTION---\")\n",
        "    state_dict = state[\"keys\"]\n",
        "    question = state_dict[\"question\"]\n",
        "    code_solution = state_dict[\"generation\"]\n",
        "    prefix = code_solution[0].prefix\n",
        "    imports = code_solution[0].imports\n",
        "    code = code_solution[0].code\n",
        "    code_block = imports + \"\\n\" + code\n",
        "    iter = state_dict[\"iterations\"]\n",
        "\n",
        "    try:\n",
        "        # Attempt to execute the code block\n",
        "        exec(code_block)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
        "        # Catch any error during execution (e.g., ImportError, SyntaxError)\n",
        "        error = f\"Execution error: {e}\"\n",
        "        if \"error\" in state_dict:\n",
        "            error_prev_runs = state_dict[\"error\"]\n",
        "            error = error_prev_runs + \"\\n --- Most recent run error --- \\n\" + error\n",
        "    else:\n",
        "        print(\"---CODE BLOCK CHECK: SUCCESS---\")\n",
        "        # No errors occurred\n",
        "        error = \"None\"\n",
        "\n",
        "    return {\n",
        "        \"keys\": {\n",
        "            \"generation\": code_solution,\n",
        "            \"question\": question,\n",
        "            \"error\": error,\n",
        "            \"prefix\": prefix,\n",
        "            \"imports\": imports,\n",
        "            \"iterations\": iter,\n",
        "            \"code\": code,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HMZ5bFSPffxd"
      },
      "outputs": [],
      "source": [
        "### Edges\n",
        "\n",
        "\n",
        "def decide_to_check_code_exec(state: GraphState):\n",
        "    \"\"\"\n",
        "    Determines whether to test code execution, or re-try answer generation.\n",
        "\n",
        "    Args:\n",
        "       state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---DECIDE TO TEST CODE EXECUTION---\")\n",
        "    state_dict = state[\"keys\"]\n",
        "    error = state_dict[\"error\"]\n",
        "\n",
        "    if error == \"None\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\"---DECISION: TEST CODE EXECUTION---\")\n",
        "        return \"check_code_execution\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "def decide_to_finish(state: GraphState):\n",
        "    \"\"\"\n",
        "    Determines whether to finish (re-try code 3 times.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---DECIDE TO TEST CODE EXECUTION---\")\n",
        "    state_dict = state[\"keys\"]\n",
        "    error = state_dict[\"error\"]\n",
        "    iter = state_dict[\"iterations\"]\n",
        "\n",
        "    if error == \"None\" or iter == 3:\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\"---DECISION: TEST CODE EXECUTION---\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
        "        return \"generate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TY-DWiopiRKd"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"generate\", generate)  # generation solution\n",
        "workflow.add_node(\"check_code_imports\", check_code_imports)  # check imports\n",
        "workflow.add_node(\"check_code_execution\", check_code_execution)  # check execution\n",
        "\n",
        "# Build graph\n",
        "workflow.set_entry_point(\"generate\")\n",
        "workflow.add_edge(\"generate\", \"check_code_imports\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_code_imports\",\n",
        "    decide_to_check_code_exec,\n",
        "    {\n",
        "        \"check_code_execution\": \"check_code_execution\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_code_execution\",\n",
        "    decide_to_finish,\n",
        "    {\n",
        "        \"end\": END,\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p8554h93iVII"
      },
      "outputs": [],
      "source": [
        "import langsmith\n",
        "\n",
        "client = langsmith.Client()\n",
        "\n",
        "public_dataset = (\n",
        "    \"https://smith.langchain.com/public/326674a6-62bd-462d-88ae-eea49d503f9d/d?tab=0&paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D\"\n",
        ")\n",
        "# Clone the dataset to your tenant to use it\n",
        "client.clone_public_dataset(public_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IFFvXw4JiwDF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "## Data model\n",
        "class code(BaseModel):\n",
        "    \"\"\"Code output\"\"\"\n",
        "\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    code: str = Field(description=\"Code block not including import statements\")\n",
        "\n",
        "\n",
        "## LLM\n",
        "model = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "# Tool\n",
        "code_tool_oai = convert_to_openai_tool(code)\n",
        "\n",
        "# LLM with tool and enforce invocation\n",
        "llm_with_tool = model.bind(\n",
        "    tools=[convert_to_openai_tool(code_tool_oai)],\n",
        "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"code\"}},\n",
        ")\n",
        "\n",
        "# Parser\n",
        "parser_tool = PydanticToolsParser(tools=[code])\n",
        "\n",
        "# Create a prompt template with format instructions and the query\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"You are a coding assistant with expertise in LCEL, LangChain expression language. \\n\n",
        "        Here is a full set of LCEL documentation:\n",
        "        \\n ------- \\n\n",
        "        {context}\n",
        "        \\n ------- \\n\n",
        "        Answer the user question based on the above provided documentation. \\n\n",
        "        Ensure any code you provide can be executed with all required imports and variables defined. \\n\n",
        "        Structure your answer with a description of the code solution. \\n\n",
        "        Then list the imports. And finally list the functioning code block. \\n\n",
        "        Here is the user question: \\n --- --- --- \\n {question}\"\"\",\n",
        "    input_variables=[\"question\", \"context\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "i9QYp5xWEZAM"
      },
      "outputs": [],
      "source": [
        "def parse_answer_to_dict(x):\n",
        "    return x[0].dict()\n",
        "\n",
        "\n",
        "chain_base_case = (\n",
        "    {\n",
        "        \"context\": lambda _: concatenated_content,\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tool\n",
        "    | parser_tool\n",
        "    | RunnableLambda(parse_answer_to_dict)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrLfOdjXEgjM"
      },
      "outputs": [],
      "source": [
        "answer = chain_base_case.invoke(\"How can I write a RAG chain?\")\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFy66eBjEjEW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
